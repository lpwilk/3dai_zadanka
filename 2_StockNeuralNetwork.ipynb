{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Zadanko 2\n",
    "Okej, pierwsze płoty za koty, czy coś. Pora zakasać rękawki i spróbować zrobić coś samemu. Tym razem przyjrzymy się\n",
    "standardowemu przykładowi użycia sieci neuronowych (gdzie wyjątkowo zwykłe sieci mają dużo więcej sensu niż konwolucyjne :D).\n",
    "<br/>\n",
    "Użyjemy zbioru danych [Boston Housing](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html), który zawiera\n",
    "dane rynkowe dotyczące cen sprzedaży mieszkań w Bostonie w połowie lat 70., a naszym zadaniem będzie zbudowanie modelu\n",
    "regresyjnego (czyli po ludzku: na podstawie danych stworzymy algorytm do przwidywania ceny nowych mieszkań)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Etap 1 - Dane\n",
    "Okej, poprzednio dane miały stosunkowo prostą strukturę, tym razem zagadnienie jest o 1 kroczek cięższe. Spokojnie...\n",
    "nie ma się czego obawiać ;). Przyjrzyjmy się co mamy do dyspozycji ^^."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_price), (test_data, test_price) = boston_housing.load_data()\n",
    "train_data.shape, test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No dobra, czyli widzimy że mamy do dyspozycji 404 próbki uczące i 102 testowe. Poza tym wiemy, że każde mieszkanie opisuje\n",
    "13 \"atrybutów\" (w ML nazywamy każdy taki *atrybut* **cechą**). Opis atrybutów, znajdziecie pod linkiem wyżej.\n",
    "<br/>\n",
    "Spójrzmy więc na jedną porcję danych!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_data, single_price = train_data[0], train_price[0]\n",
    "single_data, single_price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nic szczególnego, tablica i 13 wartości, a z drugiej strony kasa... Kto by się spodziewał :P. Tak jak poprzednio dane\n",
    "wymagają małej obróbki (podpowiedź: normalizacji), ale żeby utrwalić sobie pracę z danymi zostawię to wam 3:)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "train_data = ...\n",
    "test_data = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Etap 2 - Sieć neuronowa\n",
    "Mając przygotowane dane, standardowo przechodzimy do zdefiniowania naszej sieci.\n",
    "Trochę jak poprzednio stworzę dla was sieć, która wykonuje swoje zadanie, ale nie najlepiej na świecie. A dodatkową zabawą\n",
    "dla was będzie próbowanie, czy uda wam się wykręcić więcej ;)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = models.Sequential([\n",
    "    Dense(4, activation='sigmoid', input_shape=(train_data.shape[1],)),\n",
    "    Dense(2, activation='sigmoid'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Słowem uzupełnienia... Żebyście w zabawie nie zagalopowali się za daleko to wprowadzę ograniczenia:\n",
    "<ul>\n",
    "    <li> Używamy tylko warstwy Dense. W przypadku klasycznych sieci można w prawdzie użyć jeszcze co najmniej dwóch innych\n",
    "    typów warstw, ale to już troche cięższe zagadnienie.\n",
    "    <li> Zagadnienie jak na sieć neuronową jest stosunkowo proste, więc budowanie sieci z 1000 warstw nie ukręci nic\n",
    "    o wiele lepszego. Ja dałem dwie warstwy ukryte, ale nie mówię, że to słuszne rozwiązanie. Umówmy się, że maksymalnie\n",
    "    używamy 8 warstw (co nie znaczy, że musicie tyle użyć!).\n",
    "    <li> Jeżeli popatrzymy na to jak działa sieć to przyjmuje ona 13 wartości, potem majstruje nimi w jakiś baaardzo\n",
    "    pokrętny sposób, a na końcu ma nam wypluć jedną liczbę (np. 7000 USD). Dlatego na końcu jest warstwa Dense(1).\n",
    "    W trzech słowach: Nie ruszamy Dense(1)! Ta warstwa musi być na końcu żeby sieć działała.\n",
    "<ul/>\n",
    "Skoro wolno używać tylko jednej warstwy to pewnie trzeba trochę popatrzeć co można w niej robić. Tutaj też trochę wam\n",
    "podpowiem. Kluczowym zagadnieniem jest funkcja aktywacji (jeżeli, ktoś jeszcze nie wie co to, to czas doczytać ;)).\n",
    "\n",
    "Umówmy się, że optimum będzie przeczytanie i przetestowanie dwóch funkcji aktywacji: \"sigmoid\" i \"relu\", ale nie stawiam\n",
    "górnego limitu ;). To samo tyczy się samych atrybutów warstwy Dense - nie oczekuję, że będziecie je wszystkie ustawiać,\n",
    "ale jeżeli ktoś będzie miał ochotę, to odsyłam do dokumentacji Keras i popatrzcie co można zmieniać ;).\n",
    "\n",
    "Dobra, przejdźmy do kompilacji modelu. Tutaj dla odmiany wszystko jest jak trzeba."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Co robi teraz sieć? Używając metody spadku gradientowego, uczy się tak żeby... zgadza się - żeby zminimalizować średni\n",
    "błąd kwadratowy. Ahh, stara dobra metoda najmniejszych kwadratów..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Etap 3 - uczenie i walidacja\n",
    "\n",
    "Okej, jedziemy z uczeniem. Tutaj znów wszystko jest na swoim miejscu. Uczymy sieć przez 80 epok, sieć bierze paczkę po 16\n",
    "wpisów, przewiduje każdy z nich, a potem dostosowuje parametry tak, żeby troche zmniejszyć błąd dla każdego z wpisów.\n",
    "Tutaj może powiem tylko, że batch_size jest stosunkowo ważnym parametrem, ponieważ ma wpływ na to jak \"gładko\" uczy się\n",
    "sieć. Ale o tym może więcej powiem później ;)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=train_data,\n",
    "    y=train_price,\n",
    "    epochs=80,\n",
    "    batch_size=16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No i dla porządku wyrysujmy wykres, żeby zobaczyć jak szło uczenie."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.set(\n",
    "    title='Model loss',\n",
    "    xlabel='Epoch',\n",
    "    ylabel='Loss'\n",
    ")\n",
    "\n",
    "ax2.plot(history.history['mae'])\n",
    "ax2.set(\n",
    "    title='Model average error',\n",
    "    xlabel='Epoch',\n",
    "    ylabel='Error [kUSD]'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(test_data, test_price)\n",
    "print(f\"Test results:\\n\\tLoss: {loss}\\n\\Mean average error: {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Podsumowanie\n",
    "To już ostatni z notebooków o klasycznych sieciach. W następnym przejdziemy już do obrazków, a w międzyczasie będziemy\n",
    "uzupełniać moje niedomówienia :P.\n",
    "<br/>\n",
    "Z tym cackiem zostawiam was na najbliższą chwilę. Pochylcie się nad zagadnieniami które zaznaczyłem, a jeżeli coś będzie\n",
    "niejasne to dzielcie się tym na czacie, a razem na pewno dojdziemy do jakichś ciekawych wniosków."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aaa...\n",
    "\n",
    "### Zadanko dla ciekawskich\n",
    "**BYĆ CIEKAWSKIM I PRÓBOWAĆ CZYTAĆ (ALBO NAJLEPIEJ PYTAĆ) O WSZYSTKIM CO BUDZI PYTANIA!**"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}